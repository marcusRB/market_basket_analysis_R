---
title: "market_basket_analysis_R"
output: html_document
---

# Dataset

Implementing MBA/Association Rule Mining using R
In this tutorial, you will use a dataset from the UCI Machine Learning Repository. The dataset is called Online-Retail, and you can download it from here. The dataset contains transaction data from 01/12/2010 to 09/12/2011 for a UK-based registered non-store online retail. The reason for using this and not R dataset is that you are more likely to receive retail data in this form on which you will have to apply data pre-processing.



# Loading Libraries
First, you will load the libraries required. A short description of the libraries (taken from Here) is given in the following table, so you know what each library does:

Package	Description
arules	Provides the infrastructure for representing, manipulating and analyzing transaction data and patterns (frequent itemsets and association rules).
arulesViz	Extends package 'arules' with various visualization techniques for association rules and item-sets. The package also includes several interactive visualizations for rule exploration.
tidyverse	The tidyverse is an opinionated collection of R packages designed for data science
readxl	Read Excel Files in R
plyr	Tools for Splitting, Applying and Combining Data
ggplot2	Create graphics and charts
knitr	Dynamic Report generation in R
lubridate	Lubridate is an R package that makes it easier to work with dates and times.



```{r setup, include=FALSE}

#install and load package arules
#install.packages("arules")
library(arules)
#install and load arulesViz
#install.packages("arulesViz")
library(arulesViz)
#install and load tidyverse
#install.packages("tidyverse")
library(tidyverse)
#install and load readxml
#install.packages("readxml")
library(readxl)
#install and load knitr
#install.packages("knitr")
library(knitr)
#load ggplot2 as it comes in tidyverse
library(ggplot2)
#install and load lubridate
#install.packages("lubridate")
library(lubridate)
#install and load plyr
#install.packages("plyr")
library(plyr)
library(dplyr)
```

#Data Pre-processing
Use read_excel(path to file) to read the dataset from the downloaded file into R. Give your complete path to file including filename in read_excel(path-to-file-with-filename)


```{r,cache=TRUE,warning = FALSE,message=FALSE} 
## Carga del Data Set desde la fuente Original

library("readxl")
temp = tempfile(fileext = ".xlsx")
dataURL <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx"
download.file(dataURL, destfile=temp, mode='wb')

data <- readxl::read_excel(temp, sheet = 1 )
head(data)
dim(data)
```

```{r,cache=TRUE,warning = FALSE,message=FALSE} 
#complete.cases(data) will return a logical vector indicating which rows have no missing values. Then use the vector to get only rows that are complete using retail[,].
retail <- data
retail <- retail[complete.cases(retail), ]
#mutate function is from dplyr package. It is used to edit or add new columns to dataframe. Here Description column is being converted to factor column. as.factor converts column to factor column. %>% is an operator with which you may pipe values to another function or expression
retail %>% mutate(Description = as.factor(Description))
```



```{r,cache=TRUE,warning = FALSE,message=FALSE} 
retail %>% mutate(Country = as.factor(Country))

#Converts character data to date. Store InvoiceDate as date in new variable
retail$Date <- as.Date(retail$InvoiceDate)
#Extract time from InvoiceDate and store in another variable
TransTime<- format(retail$InvoiceDate,"%H:%M:%S")
#Convert and edit InvoiceNo into numeric
InvoiceNo <- as.numeric(as.character(retail$InvoiceNo))
```


```{r}
#Bind new columns TransTime and InvoiceNo into dataframe retail
cbind(retail,TransTime)
cbind(retail,InvoiceNo)
#get a glimpse of your data
glimpse(retail)
```

Now, dataframe retail will contain 10 attributes, with two additional attributes Date and Time.

Before applying MBA/Association Rule mining, we need to convert dataframe into transaction data so that all items that are bought together in one invoice are in one row. You can see in glimpse output that each transaction is in atomic form, that is all products belonging to one invoice are atomic as in relational databases. This format is also called as the singles format.

What you need to do is group data in the retail dataframe either by CustomerID, CustomerID, and Date or you can also group data using InvoiceNo and Date. We need this grouping and apply a function on it and store the output in another dataframe. This can be done by ddply.

The following lines of code will combine all products from one InvoiceNo and date and combine all products from that InvoiceNo and date as one row, with each item, separated by ,





```{r}
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
transactionData <- ddply(retail,c("InvoiceNo","Date"),
                       function(df1)paste(df1$Description,
                       collapse = ","))
#The R function paste() concatenates vectors to character and separated results using collapse=[any optional charcater string ]. Here ',' is used
transactionData
```

Next, as InvoiceNo and Date will not be of any use in the rule mining, you can set them to NULL.

```{r}
#set column InvoiceNo of dataframe transactionData  
transactionData$InvoiceNo <- NULL
#set column Date of dataframe transactionData
transactionData$Date <- NULL
#Rename column to items
colnames(transactionData) <- c("items")
#Show Dataframe transactionData
transactionData
```

This format for transaction data is called the basket format. Next, you have to store this transaction data into a .csv (Comma Separated Values) file. For this, write.csv()

```{r}
write.csv(transactionData, 'transactionData.csv', quote = FALSE, row.names = TRUE)
#transactionData: Data to be written
#"D:/Documents/market_basket.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes. If FALSE nothing will be quoted
#row.names: either a logical value indicating whether the row names of x are to be written along with x, or a character vector of row names to be written.
```

Next, you have to load this transaction data into an object of the transaction class. This is done by using the R function read.transactions of the arules package.

The following line of code will take transaction data file D:/Documents/market_basket_transactions.csv which is in basket format and convert it into an object of the transaction class.

```{r}
tr <- read.transactions('transactionData.csv', format = 'basket', sep=',')
#sep tell how items are separated. In this case you have separated using ','
tr
summary(tr)
```

The summary(tr) is a very useful command that gives us information about our transaction object. Let's take a look at what the above output says:

There are 22191 transactions (rows) and 30066 items (columns). Note that 30066 is the product descriptions involved in the dataset and 22191 transactions are collections of these items.

Density tells the percentage of non-zero cells in a sparse matrix. You can say it as the total number of items that are purchased divided by a possible number of items in that matrix. You can calculate how many items were purchased by using density: 22191x30066x0.0005390256=359634.9


Summary can also tell you most frequent items.

Element (itemset/transaction) length distribution: This is telling you how many transactions are there for 1-itemset, for 2-itemset and so on. The first row is telling you a number of items and the second row is telling you the number of transactions.

For example, there is only 1 transaction for one item, 3597 transactions for 2 items, and there are 420 items in one transaction which is the longest.

You can generate an itemFrequencyPlot to create an item Frequency Bar Plot to view the distribution of objects based on itemMatrix (e.g., >transactions or items in >itemsets and >rules) which is our case.


```{r}
# Create an item frequency plot for the top 20 items
if (!require("RColorBrewer")) {
  # install color package of R
install.packages("RColorBrewer")
#include library RColorBrewer
library(RColorBrewer)
}
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
```

In **itemFrequencyPlot(tr,topN=20,type="absolute")** first argument is the transaction object to be plotted that is *tr*. 
*topN* allows you to plot top N highest frequency items. type can be **type="absolute" or type="relative"**. 
If absolute it will plot numeric frequencies of each item independently. 
If relative it will plot how many times these items have appeared as compared to others.


```{r}
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'), main="Relative Item Frequency Plot")

```

This plot shows that 'WHITE HANGING HEART T-LIGHT HOLDER' and 'REGENCY CAKESTAND 3 TIER' have the most sales. So to increase the sale of 'SET OF 3 CAKE TINS PANTRY DESIGN' the retailer can put it near 'REGENCY CAKESTAND 3 TIER'.

You can explore other options for itemFrequencyPlot [here](https://www.rdocumentation.org/packages/arules/versions/1.6-1/topics/itemFrequencyPlot)

## Generating Rules!
Next step is to mine the rules using the APRIORI algorithm. The function apriori() is from package arules.

```{r}
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=10))
```

The apriori will take tr as the transaction object on which mining is to be applied. parameter will allow you to set min_sup and min_confidence. The default values for parameter are minimum support of 0.1, the minimum confidence of 0.8, maximum of 10 items (maxlen).


summary(association.rules) shows the following:

- Parameter Specification: min_sup=0.001 and min_confidence=0.8 values with 10 items as max of items in a rule.

- Total number of rules: The set of 49122 rules

- Distribution of rule length: A length of 5 items has the most rules: 16424 and length of 2 items have the lowest number of rules:105

- Summary of Quality measures: Min and max values for Support, Confidence and, Lift.

- Information used for creating rules: The data, support, and confidence we provided to the algorithm.

Since there are 49122 rules, let's print only top 10:

```{r}
inspect(association.rules[1:10])
```


Using the above output, you can make analysis such as:

- 100% of the customers who bought 'WOBBLY CHICKEN' also bought 'METAL'.

- 100% of the customers who bought 'BLACK TEA' also bought SUGAR 'JARS'.

## Limiting the number and size of rules and
How can you limit the size and number of rules generated? You can do this by setting parameters in apriori. You set these parameters to adjust the number of rules you will get. If you want stronger rules, you can increase the value of conf and for more extended rules give higher value to maxlen.


```{r}
shorter.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=3))

```


Removing redundant rules
You can remove rules that are subsets of larger rules. Use the code below to remove such rules:


```{r}
subset.rules <- which(colSums(is.subset(association.rules, association.rules)) > 1) # get subset rules in vector
length(subset.rules) #> 44014 results

```


```{r}
subset.association.rules. <- association.rules[-subset.rules] # remove subset rules.

```

- which() returns the position of elements in the vector for which value is TRUE.

- colSums() forms a row and column sums for dataframes and numeric arrays.

- is.subset() Determines if elements of one vector contain all the elements of other


## Finding Rules related to given items
Sometimes, you want to work on a specific product. If you want to find out what causes influence on the purchase of item X you can use appearance option in the apriori command. **appearance** gives us options to set LHS (IF part) and RHS (THEN part) of the rule.

For example, to find what customers buy before buying 'METAL' run the following line of code:

```{r}
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),appearance = list(default="lhs",rhs="METAL"))

```

```{r}
# Here lhs=METAL because you want to find out the probability of that in how many customers buy METAL along with other items
inspect(head(metal.association.rules))
```


Similarly, to find the answer to the question Customers who bought METAL also bought.... you will keep METAL on lhs:

```{r}
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),appearance = list(lhs="METAL",default="rhs"))

```

```{r}
# Here lhs=METAL because you want to find out the probability of that in how many customers buy METAL along with other items
inspect(head(metal.association.rules))
```

## Visualizing Association Rules
Since there will be hundreds or thousands of rules generated based on data, you need a couple of ways to present your findings. ItemFrequencyPlot has already been discussed above which is also a great way to get top sold items.

Here the following visualization will be discussed:

- Scatter-Plot
- Interactive Scatter-plot
- Individual Rule Representation

### Scatter-Plot
A straight-forward visualization of association rules is to use a scatter plot using plot() of the arulesViz package. It uses Support and Confidence on the axes. In addition, third measure Lift is used by default to color (grey levels) of the points.

```{r}
# Filter rules with confidence greater than 0.4 or 40%
subRules<-association.rules[quality(association.rules)$confidence>0.4]
#Plot SubRules
plot(subRules)
```

The above plot shows that rules with high lift have low support. You can use the following options for the plot:

**plot(rulesObject, measure, shading, method)**

- *rulesObject*: the rules object to be plotted

- *measure*: Measures for rule interestingness. Can be Support, Confidence, lift or combination of these depending upon method value.

- *shading*: Measure used to color points (Support, Confidence, lift). The default is Lift.

- *method*: Visualization method to be used (scatterplot, two-key plot, matrix3D).


```{r}
plot(subRules,method="two-key plot")

```

The two-key plot uses support and confidence on x and y-axis respectively. It uses order for coloring. The order is the number of items in the rule.


### Interactive Scatter-Plot
An amazing interactive plot can be used to present your rules that use arulesViz and plotly. You can hover over each rule and view all quality measures (support, confidence and lift).

```{r}
plotly_arules(subRules)

```


### Graph-Based Visualizations
Graph-based techniques visualize association rules using vertices and edges where vertices are labeled with item names, and item sets or rules are represented as a second set of vertices. Items are connected with item-sets/rules using directed arrows. Arrows pointing from items to rule vertices indicate LHS items and an arrow from a rule to an item indicates the RHS. The size and color of vertices often represent interest measures.

Graph plots are a great way to visualize rules but tend to become congested as the number of rules increases. So it is better to visualize less number of rules with graph-based visualizations.

Let's select 10 rules from subRules having the highest confidence.

```{r}
top10subRules <- head(subRules, n = 10, by = "confidence")
```

Now, plot an interactive graph:

Note: You can make all your plots interactive using engine=htmlwidget parameter in plot

```{r}
plot(top10subRules, method = "graph",  engine = "htmlwidget")

```

From arulesViz graphs for sets of association rules can be exported in the GraphML format or as a Graphviz dot-file to be explored in tools like Gephi. For example, the 1000 rules with the highest lift are exported by:


```{r}
saveAsGraph(head(subRules, n = 1000, by = "lift"), file = "rules.graphml")
```

### Individual Rule Representation
This representation is also called as Parallel Coordinates Plot. It is useful to visualized which products along with which items cause what kind of sales.

As mentioned above, the RHS is the Consequent or the item we propose the customer will buy; the positions are in the LHS where 2 is the most recent addition to our basket and 1 is the item we previously had.

```{r}
# Filter top 20 rules with highest lift
subRules2<-head(subRules, n=20, by="lift")
plot(subRules2, method="paracoord")

```

Look at the topmost arrow. It shows that when I have 'CHILDS GARDEN SPADE PINK' and 'CHILDS GARDEN RAKE PINK' in my shopping cart, I am likely to buy 'CHILDS GARDEN RAKE BLUE' along with these as well.


Conclusion
Congratulations! You have learned APRIORI, one of the most frequently used algorithms in data mining. You have learned all about Association Rule Mining, its applications, and its applications in retailing called as Market Basket Analysis. You are also now capable of implementing Market Basket Analysis in R and presenting your association rules with some great plots! Happy learning!







